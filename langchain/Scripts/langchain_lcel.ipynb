{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7738885",
   "metadata": {},
   "source": [
    "## <a href=\"https://cursos.alura.com.br/course/langchain-python-ferramentas-llm-openai/task/156165\"><b>Utilizando LCEL para criar um roteiro de viagens</b></a><br/>\n",
    "Dar restart no kernel para limpar a memória. Não esquecer de liberar o scroll na última célula, para ver a saída completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ff682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate # Uma interação de múltiplos prompts é um chat, por isso, vamos importar um ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cbabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562675e",
   "metadata": {},
   "source": [
    "#### <b>PASSO 1 - IMPORTS e CRIAÇÃO DA LLM</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e38951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv # CARREGA A VARIÁVEL DE AMBIENTE OPENAI_KEY LIDA DO ARQUIVO .env\n",
    "\n",
    "load_dotenv() # CARREGANDO O ARQUIVO COM A OPENAI_KEY\n",
    "\n",
    "llm = ChatOpenAI( # INSTANCIANDO A LLM\n",
    "                    model=\"gpt-4.1-mini\",\n",
    "                    temperature=0.5,\n",
    "                    # 1 - OBTENDO A API KEY POR MEIO DA VARIÁVEL DE AMBIENTE OPENAI_KEY. QUE VAI FICAR ARMAZENADA NO ARQUIVO .env.\n",
    "                    # 2 - AINDA É NECESSÁRIO CARREGAR ESSE ARQUIVO. VER NA PRIMEIRA CÉLULA DO NOTEBOOK\n",
    "                    api_key=getenv(\"OPENAI_KEY\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868db52",
   "metadata": {},
   "source": [
    "#### <b>PASSO 2 - CRIANDO O <i>PROMPT TEMPLATE</i> E ASSOCIANDO UM PARSER A ELE</b></br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786694b",
   "metadata": {},
   "source": [
    "<b><ol><li>CRIANDO OS MODELOS</li></ol></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656417a",
   "metadata": {},
   "source": [
    "<ul><ul><li><b>CRIANDO O PARSER E ASSOCIANDO ELE AO MODELO DE CIDADE</b></li></ul></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field,BaseModel # pydantic -> Biblioteca para validação de dados. Garante que os dados recebidos ou manipulados estejam no formato correto,\n",
    "                                     # BaseModel -> Os modelos pydantic são classes que herdam BaseModel (https://docs-pydantic-dev.translate.goog/latest/concepts/models/?_x_tr_sl=en&_x_tr_tl=pt&_x_tr_hl=pt&_x_tr_pto=tc)\n",
    "                                     # Modelos possuem campos como atributos.\n",
    "                                     \n",
    "                                     # Field -> Para personalizar os campos do modelo (https://docs-pydantic-dev.translate.goog/latest/concepts/fields/?_x_tr_sl=en&_x_tr_tl=pt&_x_tr_hl=pt&_x_tr_pto=tc)\n",
    "\n",
    "class Destino(BaseModel): # A nossa classe vai estender a classe BaseModel, que terá dois campos a cidade e o motivo de visitá-la\n",
    "    cidade: str = Field(description=\"cidade a visitar\") # Descrição do campo. Apenas informativo\n",
    "    motivo: str = Field(description=\"motivo pelo qual é interessante visitar\") # Descrição do campo. Apenas informativo  \n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser # EXISTEM DIVERSOS OUTPUT PARSERS (https://python.langchain.com/docs/concepts/output_parsers/)\n",
    "\n",
    "parseador = JsonOutputParser(pydantic_object=Destino) # DOCUMENTAÇÃO JsonOutputParser (https://python.langchain.com/docs/how_to/output_parser_json)\n",
    "\n",
    "template_cidade = PromptTemplate(\n",
    "                                    template=\"\"\"Sugira uma cidade, dado o meu interesse por {interesse}.\n",
    "                                    {formatacao_de_saida_da_ia}\"\"\", # AQUI TEMOS UMA VARÍAVEL PARCIAL. UTLIZAÇÃO DA TÉCNICA DE SHOTS PARA PROMPTS\n",
    "                                    input_variables=[\"interesse\"],\n",
    "                                    # A VARÍAVEL PARCIAL É UM DICIONÁRIO. FUNCIONA COMO O SHOT\n",
    "                                    partial_variables={\"formatacao_de_saida_da_ia\":parseador.get_format_instructions()}, # PASSANDO O PARSEADOR PARA A VARIÁVEL FORMATAÇÃO DE SAÍDA.\n",
    "                                                                                                   \n",
    "                                ) # INSTANCIANDO PromptTemplate e INICIANDO A PARTIR DE UM TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3aa8f",
   "metadata": {},
   "source": [
    "<ul><ul><li><b>CRIANDO O MODELO PARA RESTAURANTES</b></li></ul></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4341a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_restaurante = ChatPromptTemplate.from_template(\"Sugira restaurantes populares entre locais na {cidade}\") # INSTANCIANDO ChatPromptTemplate e INICIANDO A PARTIR DE UM TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa64bdb",
   "metadata": {},
   "source": [
    "<ul><ul><li><b>CRIANDO O MODELO CULTURAL</b></li></ul></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f74086",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_cultural = ChatPromptTemplate.from_template(\"Sugira atividades e locais culturais em {cidade}\") # INSTANCIANDO ChatPromptTemplate e INICIANDO A PARTIR DE UM TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0851fe2",
   "metadata": {},
   "source": [
    "#### <b>PASSO 3 - CRIANDO AS CADEIAS</b></br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb11744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "cadeia_cidade = LLMChain(llm=llm,prompt=template_cidade)\n",
    "cadeia_restaurante = LLMChain(llm=llm,prompt=template_restaurante)\n",
    "cadeia_cultural = LLMChain(llm=llm,prompt=template_cultural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2c37e",
   "metadata": {},
   "source": [
    "<b><ul><li>CRIANDO A CADEIA GERAL (SimpleSequentialChain)</li></ul></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8614511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "cadeia = SimpleSequentialChain(chains=[cadeia_cidade,cadeia_restaurante,cadeia_cultural])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847f1dd",
   "metadata": {},
   "source": [
    "#### <b>PASSO 4 - INVOCANDO A CADEIA GERAL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = cadeia.invoke(\"praias\") # DIFERENTE DO QUE ACONTECEU COM O PROMPT TEMPLATE, AQUI INVOCAMOS A CADEIA, E COMTÉM UM TEMPLATE, E ELA INVOCA A LLM\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98bd8b1",
   "metadata": {},
   "source": [
    "#### <b>OBTENDO APENAS O CONTEÚDO DA MENSAGEM</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b472304",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resposta['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0351ab",
   "metadata": {},
   "source": [
    "<ul><li><b>USANDO O MODO DEBUG</b></li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffac78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "set_debug(True)\n",
    "\n",
    "resposta = cadeia.invoke(input=\"praias\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3175d67",
   "metadata": {},
   "source": [
    "<b>RESULTADO DOS PROMPTS</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
