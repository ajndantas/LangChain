{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7738885",
   "metadata": {},
   "source": [
    "## [Gerando dicas de viagem com a OpenAI e o GPT 3.5 - parte 2](\"https://cursos.alura.com.br/course/langchain-python-ferramentas-llm-openai/task/156160\")<br/>\n",
    "##### <li> O objetivo será criar um cliente, agora usando o LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab88ca4",
   "metadata": {},
   "source": [
    "### <b>CRIANDO CLIENTE USANDO O LANGCHAIN</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46253e49",
   "metadata": {},
   "source": [
    "#### <b>PASSO 1 - IMPORTS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc6f24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI # JÁ PEDE A API DE CHAT DIRETO\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv # CARREGA A VARIÁVEL DE AMBIENTE OPENAI_KEY LIDA DO ARQUIVO .env\n",
    "\n",
    "load_dotenv() # CARREGANDO O ARQUIVO COM A OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41322662",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_dias = 7\n",
    "numero_de_criancas = 2\n",
    "atividade = \"praia\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868db52",
   "metadata": {},
   "source": [
    "#### PASSO 2 - CRIANDO O PROMPT</b></br>\n",
    "##### <li> Sem prompt template</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460061fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crie um roteiro de viagem de 7 dias, para uma família com 2 crianças, que gostam de praia e cite a cidade.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"Crie um roteiro de viagem de {numero_de_dias} dias, para uma família com {numero_de_criancas} crianças, que gostam de {atividade} e cite a cidade.\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ac604",
   "metadata": {},
   "source": [
    "##### [<li>Com prompt template</li></b>](\"https://cursos.alura.com.br/course/langchain-python-ferramentas-llm-openai/task/156162\")\n",
    "<ul><li>As vantagens do uso de prompt templates são:</li></ul>\n",
    "<ul><ul><li>Padronização: Garante consistência na forma como as instruções são passadas ao modelo.</li></ul></ul>\n",
    "<ul><ul><li>Eficiência: Evita retrabalho ao reutilizar estruturas prontas para diferentes entradas.</ul></ul></li>\n",
    "<ul><ul><li>Escalabilidade: Facilita a automação e aplicação em larga escala (ex.: via scripts ou APIs).</ul></ul></li>\n",
    "<ul><ul><li>Qualidade: Aumenta a chance de obter respostas mais precisas e relevantes, ao estruturar melhor o contexto.</ul></ul></li>\n",
    "<ul><ul><li>Facilidade de teste e ajuste: Permite comparar variações sistemáticas do prompt para otimização.</ul></ul></li></br>\n",
    "\n",
    "<ul><li>Esses templates são especialmente úteis em aplicações como chatbots, geração de conteúdo e classificação de dados.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c229c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[32m      3\u001b[39m template = \u001b[33m\"\u001b[39m\u001b[33mCrie um roteiro de viagem de \u001b[39m\u001b[38;5;132;01m{dias}\u001b[39;00m\u001b[33m dias, para uma família com \u001b[39m\u001b[38;5;132;01m{criancas}\u001b[39;00m\u001b[33m crianças, que gostam de \u001b[39m\u001b[38;5;132;01m{atividade}\u001b[39;00m\u001b[33m e cite a cidade.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# TEMPLATE É UM MODELO DE FORMULÁRIO\u001b[39;00m\n\u001b[32m      4\u001b[39m                                                                                                                                             \u001b[38;5;66;03m# PERCEBA QUE NÃO ESTÁ\u001b[39;00m\n\u001b[32m      5\u001b[39m                                                                                                                                             \u001b[38;5;66;03m# COM O f NO INÍCIO, \u001b[39;00m\n\u001b[32m      6\u001b[39m                                                                                                                                             \u001b[38;5;66;03m# PARA PEGAR VALORES DE \u001b[39;00m\n\u001b[32m      7\u001b[39m                                                                                                                                             \u001b[38;5;66;03m# VARIÁVIES\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"Crie um roteiro de viagem de {dias} dias, para uma família com {criancas} crianças, que gostam de {atividade} e cite a cidade.\" # TEMPLATE É UM MODELO DE FORMULÁRIO\n",
    "                                                                                                                                            # PERCEBA QUE NÃO ESTÁ\n",
    "                                                                                                                                            # COM O f NO INÍCIO, \n",
    "                                                                                                                                            # PARA PEGAR VALORES DE \n",
    "                                                                                                                                            # VARIÁVIES\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template) # CRIANDO A PARTIR DE UMA STRING, PODE-SE CRIAR A PARTIR DE OUTRAS (Ex: Arquivo. \n",
    "                                                         # Documentação https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html\n",
    "                                                         \n",
    "# FORMATANDO O prompt_template\n",
    "prompt_template.format(dias=numero_de_dias, criancas=numero_de_criancas, atividade=atividade)\n",
    "\n",
    "prompt = prompt_template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2ca92",
   "metadata": {},
   "source": [
    "#### <b>PASSO 3 - INSTANCIANDO O LLM</b></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( # INSTANCIANDO A LLM\n",
    "                    model=\"gpt-4.1-mini\",\n",
    "                    temperature=0.5,\n",
    "                    # 1 - OBTENDO A API KEY POR MEIO DA VARIÁVEL DE AMBIENTE OPENAI_KEY. QUE VAI FICAR ARMAZENADA NO ARQUIVO .env.\n",
    "                    # 2 - AINDA É NECESSÁRIO CARREGAR ESSE ARQUIVO.\n",
    "                    api_key=getenv(\"OPENAI_KEY\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847f1dd",
   "metadata": {},
   "source": [
    "#### <b>PASSO 4 - INVOCANDO</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE EU QUISER UTILIZAR A MINHA LLM, BASTA INVOCAR ALGO NELA\n",
    "resposta = llm.invoke(prompt)\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5eb63",
   "metadata": {},
   "source": [
    "<b>IMPLEMENTAÇÃO MAIS LIMPA DO QUE USANDO A API</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
